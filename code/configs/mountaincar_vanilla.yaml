# Minimal vanilla PPO config for a 10k-step smoke test on MountainCar.
seed: 1
device: "cpu"
method: "vanilla"

env:
  id: "MountainCar-v0"
  vec_envs: 8
  frame_skip: 1
  domain_randomization: false
  discrete_actions: true

ppo:
  steps_per_update: 128     # per-env steps; total per update = 128 * vec_envs
  minibatches: 32
  epochs: 4
  learning_rate: 3.0e-4
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  entropy_coef: 0.01        # encourage exploration for sparse-reward MC

intrinsic:
  # Explicitly zeroed for vanilla
  eta: 0.0

adaptation:
  enabled: false

evaluation:
  interval_steps: 50000
  episodes: 5

logging:
  tb: false                 # CSV-only for lightweight smoke runs
  csv_interval: 1000
  checkpoint_interval: 10000
